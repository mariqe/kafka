# Пайплайн миграции данных PostgreSQL → Kafka → ClickHouse

## Описание решения

В базе данных PostgreSQL хранится таблица user_logins. В ней содержатся события пользователей, такие как логин, регистрация, покупка и т.д. Каждый раз, когда необходимо перенести эти события из PostgreSQL в другую систему (например, ClickHouse), можно воспользоваться Kafka как промежуточным звеном для передачи сообщений. Однако, в реальных задачах возникает риск повторной отправки уже обработанных данных. Чтобы избежать дублирования, нужно использовать дополнительное логическое поле в таблице — sent_to_kafka BOOLEAN, которое будет сигнализировать, были ли данные уже отправлены в Kafka.

Решение гарантирует однократную доставку событий из PostgreSQL в ClickHouse через Kafka.

**Особенности:**
- Защита от дублирования на стороне продюсера через флаг `sent_to_kafka`
- Транзакционность операций в PostgreSQL
- Подтверждение доставки в Kafka
- Управление смещениями (offsets) через group_id консьюмера
- Логирование процесса обработки

## Запуск пайплайна

1. **Требования**:
   - Python 3.8+
   - Установленные пакеты: `psycopg2-binary kafka-python clickhouse-connect`

2. **Установка зависимостей**:
   ```bash
   pip install psycopg2-binary kafka-python clickhouse-connect
